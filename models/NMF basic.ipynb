{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non negative Matrix Factorization(NMF)\n",
    "\n",
    "* Download the [Thunder](http://docs.thunder-project.org/introduction) package using the following commands\n",
    "    * `pip install thunder-python`\n",
    "    * `pip install thunder-extraction`\n",
    "* Download the test dataset and run this code.\n",
    "* The below NMF code is a brief example implemented by [freeman lab](https://gist.github.com/freeman-lab/330183fdb0ea7f4103deddc9fae18113) for this very dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Class to download and setup data\n",
    "* A class is built that checks if data folder is present and if not downloads and setups the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "path = 'e:/project3/'\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    '''\n",
    "    Downloads the data and have the data prepared.\n",
    "    '''\n",
    "    def __init__(self, download_link = 'gs://uga-dsp/project3/' ):\n",
    "        self.download_link = download_link\n",
    "        self.train_path = self.get_train_path()\n",
    "        self.test_path = self.get_test_path()\n",
    "        \n",
    "        if os.path.exists(\"data\"):\n",
    "            print('Data Folder is ready')\n",
    "        else:\n",
    "            self.download_data(download_link)\n",
    "        \n",
    "    def download_data(self, download_link):\n",
    "        if os.path.exists('download_zip123'):\n",
    "            self.extract_zip_data()\n",
    "        else:\n",
    "            print(\"==> Downloading data\")\n",
    "            subprocess.call('mkdir download_zip123', shell = True)\n",
    "            subprocess.call('/usr/bin/gsutil -m cp -r ' + download_link + '/download_zip',  shell=True)\n",
    "            self.extract_zip_data()\n",
    "\n",
    "        \n",
    "    def extract_zip_data(self):\n",
    "        files = os.listdir(path+'download_zip/')\n",
    "        for file in files:\n",
    "            print(\"Extracting \"+file)\n",
    "            zip_ref = zipfile.ZipFile(path +'download_zip/'+ file, 'r')\n",
    "            if file[-8:] == 'test.zip':\n",
    "                zip_ref.extractall(d1.test_path)\n",
    "            else:\n",
    "                zip_ref.extractall(d1.train_path)\n",
    "            zip_ref.close()            \n",
    "        \n",
    "    def get_train_path(self):\n",
    "        return 'e:/project3/data/train/'\n",
    "    \n",
    "    def get_test_path(self):\n",
    "        return 'e:/project3/data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import thunder as td\n",
    "from extraction import NMF\n",
    "import os\n",
    "\n",
    "d1=Loader()\n",
    "\n",
    "\n",
    "def matrix_factorisation():\n",
    "    datasets =os.listdir(d1.test_path)\n",
    "    submission = []\n",
    "    algorithm_args = dict(k = 5,\n",
    "                          percentile = 99,\n",
    "                          max_iter=50,\n",
    "                          overlap=0.1)\n",
    "\n",
    "    model_args = dict(chunk_size=(50,50),\n",
    "                      padding=(25,25))\n",
    "\n",
    "    for dataset in datasets:\n",
    "        print('processing dataset: %s' % dataset)\n",
    "        print('loading')\n",
    "        \n",
    "        data = td.images.fromtif(d1.test_path + dataset + '/images', ext='tiff')\n",
    "        print('analyzing')\n",
    "\n",
    "        algorithm = NMF(**algorithm_args)\n",
    "        model = algorithm.fit(data, **model_args)\n",
    "        merged = model.merge(algorithm_args['overlap'])\n",
    "        \n",
    "        print('found %g regions' % merged.regions.count)\n",
    "        \n",
    "        regions = [{'coordinates': region.coordinates.tolist()} \n",
    "                   for region in merged.regions]\n",
    "        result = {'dataset': dataset, 'regions': regions}\n",
    "        \n",
    "        submission.append(result)\n",
    "\n",
    "    print('writing results')\n",
    "    with open('submission3.json', 'w') as f:\n",
    "        f.write(json.dumps(submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
